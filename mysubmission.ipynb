{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0c8b419-003f-49e0-a143-12a8dd382a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.14.0 in ./envs/tf2/lib/python3.11/site-packages (2.14.0)\n",
      "Requirement already satisfied: wget in ./envs/tf2/lib/python3.11/site-packages (3.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./envs/tf2/lib/python3.11/site-packages (from tensorflow==2.14.0) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./envs/tf2/lib/python3.11/site-packages (from tensorflow==2.14.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in ./envs/tf2/lib/python3.11/site-packages (from tensorflow==2.14.0) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./envs/tf2/lib/python3.11/site-packages (from tensorflow==2.14.0) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./envs/tf2/lib/python3.11/site-packages (from tensorflow==2.14.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./envs/tf2/lib/python3.11/site-packages (from tensorflow==2.14.0) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./envs/tf2/lib/python3.11/site-packages (from tensorflow==2.14.0) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in ./envs/tf2/lib/python3.11/site-packages (from tensorflow==2.14.0) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in ./envs/tf2/lib/python3.11/site-packages (from tensorflow==2.14.0) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./envs/tf2/lib/python3.11/site-packages (from tensorflow==2.14.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in ./envs/tf2/lib/python3.11/site-packages (from tensorflow==2.14.0) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./envs/tf2/lib/python3.11/site-packages (from tensorflow==2.14.0) (3.20.3)\n",
      "Requirement already satisfied: setuptools in ./envs/tf2/lib/python3.11/site-packages (from tensorflow==2.14.0) (68.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in ./envs/tf2/lib/python3.11/site-packages (from tensorflow==2.14.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./envs/tf2/lib/python3.11/site-packages (from tensorflow==2.14.0) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./envs/tf2/lib/python3.11/site-packages (from tensorflow==2.14.0) (4.9.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in ./envs/tf2/lib/python3.11/site-packages (from tensorflow==2.14.0) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./envs/tf2/lib/python3.11/site-packages (from tensorflow==2.14.0) (0.35.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./envs/tf2/lib/python3.11/site-packages (from tensorflow==2.14.0) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in ./envs/tf2/lib/python3.11/site-packages (from tensorflow==2.14.0) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in ./envs/tf2/lib/python3.11/site-packages (from tensorflow==2.14.0) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in ./envs/tf2/lib/python3.11/site-packages (from tensorflow==2.14.0) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./envs/tf2/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow==2.14.0) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./envs/tf2/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.26.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./envs/tf2/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./envs/tf2/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./envs/tf2/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./envs/tf2/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./envs/tf2/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./envs/tf2/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./envs/tf2/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./envs/tf2/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./envs/tf2/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./envs/tf2/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./envs/tf2/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./envs/tf2/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./envs/tf2/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./envs/tf2/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in ./envs/tf2/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./envs/tf2/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9659e4e0-1174-4387-8c7d-4db1e9816376",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = '/bohr/ai4spulseeis-lr97/v5'\n",
    "\n",
    "import pickle\n",
    "from os import listdir\n",
    "from os.path import exists, join, splitext\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from wget import download\n",
    "from tqdm import tqdm\n",
    "\n",
    "if not exists('predictor.h5'): download('https://raw.githubusercontent.com/breadbread1984/EIS_prediction/main/predictor.h5')\n",
    "if not exists('sos.npy'): download('https://raw.githubusercontent.com/breadbread1984/EIS_prediction/main/sos.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0118facb-ddaf-48e7-8fcc-d3a7906d6141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelfAttention(hidden_dim = 256, num_heads = 8, use_bias = False, drop_rate = 0.1, is_causal = True):\n",
    "  inputs = tf.keras.Input((None, hidden_dim)) # inputs.shape = (batch, seq, 256)\n",
    "  results = tf.keras.layers.Dense(hidden_dim * 3, use_bias = use_bias)(inputs) # results.shape = (batch, seq, 3 * 256)\n",
    "  results = tf.keras.layers.Reshape((-1, 3, num_heads, hidden_dim // num_heads))(results) # results.shape = (batch, seq, 3, 8, 32)\n",
    "  results = tf.keras.layers.Lambda(lambda x: tf.transpose(x, (0,2,3,1,4)))(results) # results.shape = (batch, 3, 8, seq, 32)\n",
    "  q, k, v = tf.keras.layers.Lambda(lambda x: (x[:,0,...], x[:,1,...], x[:,2,...]))(results) # shape = (batch, 8, seq, 32)\n",
    "  qk = tf.keras.layers.Lambda(lambda x, s: tf.matmul(x[0], tf.transpose(x[1], (0,1,3,2))) * s, arguments = {'s': (hidden_dim // num_heads) ** -0.5})([q, k]) # qk.shape = (batch, 8, seq, seq)\n",
    "  if is_causal:\n",
    "    mask = tf.keras.layers.Lambda(lambda x: tf.expand_dims(\n",
    "      tf.expand_dims(\n",
    "        tf.where(\n",
    "          tf.cast(tf.linalg.band_part(tf.ones((tf.shape(x)[2],tf.shape(x)[2])), -1, 0), dtype = tf.bool),\n",
    "          tf.constant(0., dtype = tf.float32), tf.experimental.numpy.finfo(tf.float32).min),\n",
    "        axis = 0),\n",
    "      axis = 0))(k) # mask.shape = (1,1,seq,seq)\n",
    "    qk = tf.keras.layers.Add()([qk, mask])\n",
    "  attn = tf.keras.layers.Softmax(axis = -1)(qk)\n",
    "  attn = tf.keras.layers.Dropout(rate = drop_rate)(attn)\n",
    "  qkv = tf.keras.layers.Lambda(lambda x: tf.transpose(tf.matmul(x[0], x[1]), (0,2,1,3)))([attn, v]) # qkv.shape = (batch, seq, 8, 32)\n",
    "  qkv = tf.keras.layers.Reshape((-1, hidden_dim))(qkv) # qkv.shape = (batch, seq, 256)\n",
    "  results = tf.keras.layers.Dense(hidden_dim, use_bias = use_bias)(qkv)\n",
    "  results = tf.keras.layers.Dropout(drop_rate)(results)\n",
    "  return tf.keras.Model(inputs = inputs, outputs = results)\n",
    "\n",
    "def TransformerEncoder(dict_size = 1024, hidden_dim = 256, num_heads = 8, use_bias = False, layers = 2, drop_rate = 0.1):\n",
    "  inputs = tf.keras.Input((None, hidden_dim)) # inputs.shape = (batch, seq, hidden_dim)\n",
    "  results = inputs\n",
    "  for i in range(layers):\n",
    "    skip = results\n",
    "    results = tf.keras.layers.LayerNormalization()(results)\n",
    "    results = SelfAttention(hidden_dim, num_heads, use_bias, drop_rate, is_causal = False)(results)\n",
    "    results = tf.keras.layers.Add()([skip, results])\n",
    "    skip = results\n",
    "    results = tf.keras.layers.LayerNormalization()(results)\n",
    "    results = tf.keras.layers.Dense(4 * hidden_dim, activation = tf.keras.activations.gelu)(results)\n",
    "    results = tf.keras.layers.Dense(hidden_dim)(results)\n",
    "    results = tf.keras.layers.Dropout(drop_rate)(results)\n",
    "    results = tf.keras.layers.Add()([skip, results])\n",
    "  return tf.keras.Model(inputs = inputs, outputs = results)\n",
    "\n",
    "def CrossAttention(hidden_dim = 256, num_heads = 8, use_bias = False, drop_rate = 0.1):\n",
    "  code = tf.keras.Input((None, hidden_dim)) # code.shape = (batch, seq, 256)\n",
    "  inputs = tf.keras.Input((None, hidden_dim)) # inputs.shape = (batch, seq, 256)\n",
    "  code_results = tf.keras.layers.Dense(hidden_dim * 2, use_bias = use_bias)(code) # code_results.shape = (batch, seq, 2 * 256)\n",
    "  code_results = tf.keras.layers.Reshape((-1, 2, num_heads, hidden_dim // num_heads))(code_results) # code_results.shape = (batch, seq, 2, 8, 32)\n",
    "  code_results = tf.keras.layers.Lambda(lambda x: tf.transpose(x, (0,2,3,1,4)))(code_results) # code_results.shape = (batch, 2, 8, seq, 32)\n",
    "  k, v = tf.keras.layers.Lambda(lambda x: (x[:,0,...], x[:,1,...]))(code_results) # shape = (batch, 8, seq, 32)\n",
    "  results = tf.keras.layers.Dense(hidden_dim, use_bias = use_bias)(inputs) # results.shape = (batch, seq, 256)\n",
    "  results = tf.keras.layers.Reshape((-1, num_heads, hidden_dim // num_heads))(results) # results.shape = (batch, seq, 8, 32)\n",
    "  q = tf.keras.layers.Lambda(lambda x: tf.transpose(x, (0,2,1,3)))(results) # results.shape = (batch, 8, seq, 32)\n",
    "  qk = tf.keras.layers.Lambda(lambda x, s: tf.matmul(x[0], tf.transpose(x[1], (0,1,3,2))) * s, arguments = {'s': (hidden_dim // num_heads) ** -0.5})([q, k]) # qk.shape = (batch, 8, seq, seq)\n",
    "  attn = tf.keras.layers.Softmax(axis = -1)(qk)\n",
    "  attn = tf.keras.layers.Dropout(rate = drop_rate)(attn)\n",
    "  qkv = tf.keras.layers.Lambda(lambda x: tf.transpose(tf.matmul(x[0], x[1]), (0,2,1,3)))([attn, v]) # qkv.shape = (batch, seq, 8, 32)\n",
    "  qkv = tf.keras.layers.Reshape((-1, hidden_dim))(qkv) # qkv.shape = (batch, seq, 256)\n",
    "  results = tf.keras.layers.Dense(hidden_dim, use_bias = use_bias)(qkv)\n",
    "  results = tf.keras.layers.Dropout(drop_rate)(results)\n",
    "  return tf.keras.Model(inputs = (code, inputs), outputs = results) \n",
    "\n",
    "def TransformerDecoder(dict_size = 1024, hidden_dim = 256, num_heads = 8, use_bias = False, layers = 2, drop_rate = 0.1):\n",
    "  code = tf.keras.Input((None, hidden_dim)) # code.shape = (batch, seq, 256)\n",
    "  inputs = tf.keras.Input((None, hidden_dim)) # inputs.shape = (batch, seq, hidden_dim)\n",
    "  results = inputs\n",
    "  for i in range(layers):\n",
    "    skip = results\n",
    "    results = tf.keras.layers.LayerNormalization()(results)\n",
    "    results = SelfAttention(hidden_dim, num_heads, use_bias, drop_rate, is_causal = True)(results)\n",
    "    results = tf.keras.layers.Add()([skip, results])\n",
    "    skip = results\n",
    "    results = tf.keras.layers.LayerNormalization()(results)\n",
    "    results = CrossAttention(hidden_dim, num_heads, use_bias, drop_rate)([code, results])\n",
    "    results = tf.keras.layers.Add()([skip, results])\n",
    "    skip = results\n",
    "    results = tf.keras.layers.LayerNormalization()(results)\n",
    "    results = tf.keras.layers.Dense(4 * hidden_dim, activation = tf.keras.activations.gelu)(results)\n",
    "    results = tf.keras.layers.Dense(hidden_dim)(results)\n",
    "    results = tf.keras.layers.Dropout(drop_rate)(results)\n",
    "    results = tf.keras.layers.Add()([skip, results])\n",
    "  return tf.keras.Model(inputs = (code, inputs), outputs = results)\n",
    "\n",
    "def Trainer(dict_size = 1024, hidden_dim = 256, num_heads = 8, use_bias = False, layers = 1, drop_rate = 0.1):\n",
    "  pulse = tf.keras.Input((None,2))\n",
    "  eis = tf.keras.Input((None,2))\n",
    "\n",
    "  pulse_embed = tf.keras.layers.Dense(hidden_dim)(pulse)\n",
    "  eis_embed = tf.keras.layers.Dense(hidden_dim)(eis)\n",
    "\n",
    "  code = TransformerEncoder(dict_size, hidden_dim, num_heads, use_bias, layers, drop_rate)(pulse_embed) # code.shape = (batch, pulse_seq, 256)\n",
    "  results = TransformerDecoder(dict_size, hidden_dim, num_heads, use_bias, layers, drop_rate)([code, eis_embed]) # results.shape = (batch, eis_seq, 256)\n",
    "  eis_update = tf.keras.layers.Dense(2)(results) # eis_tokens.shape = (batch, eis_seq, 2)\n",
    "  return tf.keras.Model(inputs = (pulse, eis), outputs = (eis_update))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e0e33e-64be-46b2-a82a-b52ee33bc272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 49/49 [02:09<00:00,  2.64s/it]\n",
      " 76%|█████████████████████████████████████████████████████████▍                  | 37/49 [01:37<00:31,  2.59s/it]"
     ]
    }
   ],
   "source": [
    "trainer = Trainer()\n",
    "trainer.load_weights('predictor.h5')\n",
    "sos = tf.constant(np.load('sos.npy'))\n",
    "\n",
    "output = open('submission.csv','w')\n",
    "output.write('test_data_number,SOC(%),EIS_real,EIS_imaginary\\n')\n",
    "for f in listdir(join(dataset, 'test_datasets')):\n",
    "  stem, ext = splitext(f)\n",
    "  if ext != '.pkl': continue\n",
    "  test_num = int(stem.replace('test_pulse_', ''))\n",
    "  with open(join(dataset, 'test_datasets', f), 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "  for SOC, pulse_samples in tqdm(data.items()):\n",
    "    soc = SOC.replace('%SOC','')\n",
    "    pulse = tf.expand_dims(tf.stack([pulse_samples['Voltage'], pulse_samples['Current']], axis = -1), axis = 0) # pulse.shape = (1, seq, 2)\n",
    "    eis = tf.tile(sos, (pulse.shape[0], 1, 1))\n",
    "    for i in range(51):\n",
    "      pred = trainer([pulse, eis])\n",
    "      eis = tf.concat([eis, pred[:,-1:,:]], axis = -2)\n",
    "    eis = eis[:,1:,:][0]\n",
    "    for e in eis:\n",
    "      output.write(','.join([str(test_num),soc,str(e[0].numpy().item()),str(e[1].numpy().item())]) + '\\n')\n",
    "output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f7c93b-6069-4262-9dc4-631b73b7d5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
